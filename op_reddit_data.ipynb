{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a221579",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Version 7.7.1 of praw is outdated. Version 7.8.1 was released Friday October 25, 2024.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting post collection...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\regor\\AppData\\Local\\Temp\\ipykernel_41880\\3112113947.py:38: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  \"created_utc\": datetime.utcfromtimestamp(submission.created_utc),\n",
      "C:\\Users\\regor\\AppData\\Local\\Temp\\ipykernel_41880\\3112113947.py:67: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  \"created_utc\": datetime.utcfromtimestamp(submission.created_utc),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 19252 unique posts.\n",
      "Collecting comments...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\regor\\AppData\\Local\\Temp\\ipykernel_41880\\3112113947.py:104: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  \"created_utc\": datetime.utcfromtimestamp(comment.created_utc),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 40000 comments.\n",
      "Data saved to anime_15k_posts.csv and anime_40k_comments.csv.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "from reddit_client import redditClient\n",
    "\n",
    "# connect to reddit\n",
    "reddit = redditClient()\n",
    "subreddit_names = [\"OnePiece\", \"anime\", \"manga\", \"animesuggestions\"]\n",
    "subreddits = [reddit.subreddit(name) for name in subreddit_names]\n",
    "\n",
    "posts = []\n",
    "comments = []\n",
    "post_ids = set()\n",
    "\n",
    "# sort types and time filters\n",
    "sort_types_with_time = ['top', 'controversial']\n",
    "sort_types_basic = ['hot', 'new', 'rising']\n",
    "time_filters = ['hour', 'day', 'week', 'month', 'year', 'all']\n",
    "\n",
    "print(\"collecting posts...\")\n",
    "\n",
    "for subreddit in subreddits:\n",
    "    for sort in sort_types_basic:\n",
    "        try:\n",
    "            submissions = getattr(subreddit, sort)(limit=2000)\n",
    "            for submission in submissions:\n",
    "                if submission.id in post_ids:\n",
    "                    continue\n",
    "                post_ids.add(submission.id)\n",
    "\n",
    "                posts.append({\n",
    "                    \"id\": submission.id,\n",
    "                    \"subreddit\": str(submission.subreddit),\n",
    "                    \"title\": submission.title,\n",
    "                    \"score\": submission.score,\n",
    "                    \"upvote_ratio\": submission.upvote_ratio,\n",
    "                    \"num_comments\": submission.num_comments,\n",
    "                    \"created_utc\": datetime.utcfromtimestamp(submission.created_utc),\n",
    "                    \"selftext\": submission.selftext,\n",
    "                    \"author\": str(submission.author),\n",
    "                    \"url\": submission.url,\n",
    "                })\n",
    "\n",
    "                if len(posts) >= 20000:\n",
    "                    break\n",
    "            if len(posts) >= 20000:\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(f\"Failed on {sort} for {subreddit.display_name}: {e}\")\n",
    "\n",
    "    for sort in sort_types_with_time:\n",
    "        for tf in time_filters:\n",
    "            try:\n",
    "                submissions = getattr(subreddit, sort)(time_filter=tf, limit=2000)\n",
    "                for submission in submissions:\n",
    "                    if submission.id in post_ids:\n",
    "                        continue\n",
    "                    post_ids.add(submission.id)\n",
    "\n",
    "                    posts.append({\n",
    "                        \"id\": submission.id,\n",
    "                        \"subreddit\": str(submission.subreddit),\n",
    "                        \"title\": submission.title,\n",
    "                        \"score\": submission.score,\n",
    "                        \"upvote_ratio\": submission.upvote_ratio,\n",
    "                        \"num_comments\": submission.num_comments,\n",
    "                        \"created_utc\": datetime.utcfromtimestamp(submission.created_utc),\n",
    "                        \"selftext\": submission.selftext,\n",
    "                        \"author\": str(submission.author),\n",
    "                        \"url\": submission.url,\n",
    "                    })\n",
    "\n",
    "                    if len(posts) >= 20000:\n",
    "                        break\n",
    "                if len(posts) >= 20000:\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                print(f\"Failed on {sort}:{tf} for {subreddit.display_name}: {e}\")\n",
    "        if len(posts) >= 20000:\n",
    "            break\n",
    "    if len(posts) >= 20000:\n",
    "        break\n",
    "\n",
    "print(f\"collected {len(posts)} posts.\")\n",
    "\n",
    "# collect comments until 40k\n",
    "print(\"collecting comments...\")\n",
    "\n",
    "for post_data in posts:\n",
    "    if len(comments) >= 40000:\n",
    "        break\n",
    "    try:\n",
    "        submission = reddit.submission(id=post_data[\"id\"])\n",
    "        submission.comments.replace_more(limit=0)\n",
    "        for comment in submission.comments:\n",
    "            if len(comments) >= 40000:\n",
    "                break\n",
    "            comments.append({\n",
    "                \"post_id\": submission.id,\n",
    "                \"comment_id\": comment.id,\n",
    "                \"body\": comment.body,\n",
    "                \"score\": comment.score,\n",
    "                \"author\": str(comment.author),\n",
    "                \"created_utc\": datetime.utcfromtimestamp(comment.created_utc),\n",
    "            })\n",
    "        time.sleep(0.5)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fetch comments for post {post_data['id']}: {e}\")\n",
    "\n",
    "print(f\"collected {len(comments)} comments.\")\n",
    "\n",
    "# save results\n",
    "pd.DataFrame(posts).to_csv(\"anime_15k_posts.csv\", index=False)\n",
    "pd.DataFrame(comments).to_csv(\"anime_40k_comments.csv\", index=False)\n",
    "\n",
    "print(\"data saved\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
